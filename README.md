# ğŸ§  Intelligent Chunking Methods for Code Documentation RAG  
**JetBrains Internship Entry Task**

---

## ğŸ“Œ Overview  
This project explores how different chunking parameters and the number of retrieved chunks affect the **recall** and **precision** of retrieved data in a retrieval-augmented generation (RAG) system.

---

## ğŸ¯ Objective  
Implement a full retrieval pipeline using open-source embedding models, and evaluate retrieval quality across varying:

- Chunking strategies  
- Chunk sizes  
- Number of retrieved chunks (top-k)

---

## ğŸ“š Dataset  
- **Corpus:** `Chatlogs (chatlogs.md)`  
- **Queries & Golden Excerpts:** `questions_df.csv`  

---

## ğŸ› ï¸ Dataset Preparation  
To enable experimentation, the dataset was processed in two distinct formats:

- **User-only messages**: Extracted and chunked only the `content` field from each message (excluding metadata).
- **Full chat format**: Retained the full dictionary, including fields like `content` and `role` (e.g., username or system/user tag), and chunked the serialized text.

Example of a raw entry:
```python
{
  "content": "These instructions apply to section-based themes (Responsive 6.0+, Retina 4.0+, Parallax 3.0+ Turbo 2.0+, Mobilia 5.0+)...",
  "role": "user"
}

```
---

## ğŸ§© Chunking Strategy  
Used the [**`FixedTokenChunker`**](https://github.com/brandonstarxel/chunking_evaluation/blob/main/chunking_evaluation/chunking/fixed_token_chunker.py) implementation, as described in the reference paper.

This method splits text into **fixed-length token chunks** using a tokenizer. Internally, it uses the **`cl100k_base` tokenizer**, which is the same tokenizer used by **OpenAI's ChatGPT-3.5-turbo** and **GPT-4-turbo**. This ensures consistency with real-world production systems and accurate token-level chunking.

The following configurations were explored:

- **Chunk Sizes (in tokens)**:
  - 10  
  - 50  
  - 100  
  - 150  
  - 200  
  - 250

- **Number of Retrieved Chunks (`k`)**:
  - 1  
  - 3  
  - 5

---

## ğŸ” Embedding Model  
Used the [**`all-MiniLM-L6-v2`**](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2) model via the `SentenceTransformers` library.

- Generated dense embeddings for all corpus chunks and queries.
- Used **cosine similarity** to compute distances between query and chunk embeddings.

---

## ğŸ“Š Evaluation Metrics  
Evaluated retrieval performance using:

- **Precision**
- **Recall**
- **F1 Score**

All scores are **averaged across 55 evaluation queries**, with **standard deviation** also reported to measure variance.


## Results

| DataSet Preparation         | Chunk Size | K  | Recall (avg Â± std)         | Precision (avg Â± std)      | F1 (avg Â± std)           |
|-----------------------------|------------|----|----------------------------|----------------------------|--------------------------|
| **User-only messages**       | 10         | 1  | 0.054 Â± 0.098              | 0.287 Â± 0.437              | 0.088 Â± 0.149            |
| **User-only messages**       | 10         | 3  | 0.114 Â± 0.148              | 0.207 Â± 0.224              | 0.137 Â± 0.154            |
| **User-only messages**       | 10         | 5  | 0.161 Â± 0.190              | 0.169 Â± 0.167              | 0.149 Â± 0.141            |
| **User-only messages**       | 50         | 1  | 0.374 Â± 0.339              | 0.442 Â± 0.396              | 0.376 Â± 0.324            |
| **User-only messages**       | 50         | 3  | 0.637 Â± 0.355              | 0.260 Â± 0.169              | 0.350 Â± 0.208            |
| **User-only messages**       | 50         | 5  | 0.733 Â± 0.335              | 0.194 Â± 0.112              | 0.293 Â± 0.156            |
| **User-only messages**       | 100        | 1  | 0.468 Â± 0.421              | 0.293 Â± 0.278              | 0.344 Â± 0.314            |
| **User-only messages**       | 100        | 3  | 0.772 Â± 0.343              | 0.211 Â± 0.148              | 0.310 Â± 0.180            |
| **User-only messages**       | 100        | 5  | 0.848 Â± 0.296              | 0.142 Â± 0.106              | 0.232 Â± 0.137            |
| **User-only messages**       | 150        | 1  | 0.517 Â± 0.438              | 0.238 Â± 0.242              | 0.307 Â± 0.285            |
| **User-only messages**       | 150        | 3  | 0.815 Â± 0.327              | 0.166 Â± 0.129              | 0.259 Â± 0.168            |
| **User-only messages**       | 150        | 5  | 0.886 Â± 0.267              | 0.112 Â± 0.098              | 0.188 Â± 0.133            |
| **User-only messages**       | 200        | 1  | 0.589 Â± 0.430              | 0.216 Â± 0.202              | 0.294 Â± 0.237            |
| **User-only messages**       | 200        | 3  | 0.893 Â± 0.272              | 0.151 Â± 0.130              | 0.238 Â± 0.159            |
| **User-only messages**       | 200        | 5  | 0.937 Â± 0.204              | 0.092 Â± 0.083              | 0.160 Â± 0.117            |
| **User-only messages**       | 250        | 1  | 0.560 Â± 0.463              | 0.172 Â± 0.200              | 0.247 Â± 0.250            |
| **User-only messages**       | 250        | 3  | 0.880 Â± 0.283              | 0.138 Â± 0.138              | 0.220 Â± 0.169            |
| **User-only messages**       | 250        | 5  | 0.946 Â± 0.185              | 0.083 Â± 0.079              | 0.145 Â± 0.108            |

